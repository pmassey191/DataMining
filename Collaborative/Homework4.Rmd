---
title: "Homework 4"
author: "Patrick Massey, Harrison Snell, Brandon Williams"
date: "5/2/2022"
output: md_document
---

```{r, echo=FALSE,results=FALSE,warning=FALSE,message=FALSE}
options(scipen=999)
library(tidyverse)
library(mosaic)
library(rsample)
library(caret)
library(modelr)
library(parallel)
library(foreach)
library(gamlr)
library(here)
library(stringr)
library(rpart)
library(rpart.plot)
library(randomForest)
library(gbm)
library(pdp)
library(here)
library(ggmap)
library(knitr)
library(LICORS)  
library(arules)  
library(arulesViz)
library(igraph)
```

# Homework 4

Patrick Massey, Harrison Snell, Brandon Williams

## Problem 1 - Wine Clustering and PCA
```{r echo=FALSE,results=FALSE,warning=FALSE,message=FALSE}
#wine <- read.csv(here("Data/wine.csv"))

```

## Problem 2 - NutrientH2O

When considering marketing to the NutrientH2O Twitter followers, there are several natural groups that emerge using unsupervised learning techniques. These groups will help NutrientH20 coordinate a marketing campaign to specific follower demographics. Before conducting principle component analysis (PCA), let's take a look at the overall trends of the tweets of the Twitter followers. 

```{r echo=FALSE}
df <- read.csv(here("data/social_marketing.csv"))
df <- select(df, -X)

# some summary statistics

avg_user <- 
  as.data.frame(sort(colMeans(df)))
avg_user <- avg_user %>% 
  rownames_to_column("tweet_cat") %>% 
  rename("avg_tweets" = "sort(colMeans(df))")


ggplot(avg_user) + 
  geom_col(aes(x = reorder(tweet_cat, -avg_tweets), y = avg_tweets)) + 
  coord_flip() +
  ylab("Average Tweets Per User") +
  xlab("Tweet Type")
```

As we might have predicted, the average user generally tweets about general, uncategorized "chatter" and some photo sharing. Nevertheless, we see some high counts in health and nutrition, cooking, politics, sports, and travel. Are there natural groupings of followers into categories? Consider the correlation matrix of tweet type organized by hierarchical clustering: 

```{r pressure, echo=FALSE}

# a heatmap visualization with sorting by hierarchical clustering
ggcorrplot::ggcorrplot(cor(df), hc.order = TRUE)
```

Some patterns emerge. Disregarding the spam/adult categories (unless NutrientH2O is considering a significant rebrand), there are clear groupings around:
  * beauty, cooking, and fashion 
  * health, nutrition, and fitness
  * family, school, religion, and parenting
  * gaming, sports, and university

Since clustering is naturally mutually exclusive and Twitter users can have multiple interests simultaneously, we choose to present a PCA on the follower base to see if these categorical patterns continue to emerge based on the components of the Tweets. An initial PCA reveals how much variance is explained by each principle component. We see the variance dropping off after 5 components, and certainly after 10 we are gaining smaller and smaller amounts of variance. 

``` {r echo=F, messages = F, results = F, warning = F}

pca1 = prcomp(df, scale=TRUE) 

#calculate total variance explained by each principal component
var_explained = pca1$sdev^2 / sum(pca1$sdev^2)

#create scree plot
qplot(c(1:36), var_explained) + 
  geom_line() + 
  xlab("Principal Component") + 
  ylab("Variance Explained") +
  ggtitle("Variance Explained by PC") +
  ylim(0, .25)
```

Running a PCA with 10 principle components gives us some pretty clear group characteristics. Let's look at the loadings for some of the components. The first principle component is once again the adult/spam group, so let's look at the high loadings for PC2. We can call this the "influencer" group: high in cooking, fashion, shopping, and beauty. Considering the overall popularity of these types of tweets among NutrientH2O followers, this would be an effective demographic to market to.


``` {r echo=F, results = T, warning = F}

pca = prcomp(df, scale=TRUE, rank=10)


# create a tidy summary of the loadings
loadings = pca$rotation %>%
  as.data.frame() %>%
  rownames_to_column('tweet')

# This looks like the spam/adult PC
# loadings %>%
#   select(tweet, PC1) %>%
#   arrange(desc(PC1))

# Let's call this the influencer - cooking, photos, fashing, shopping
loadings %>%
  select(tweet, PC2) %>%
  arrange(desc(PC2)) %>% 
  head()

```

PC3 represents the wellness demographic--people interested in health, nutrition, personal fitness, and cooking. Given NutrientH2O's brand name, this is a natural group to target in any social media marketing. 

``` {r echo=F, results = T, warning = F}

# The wellness nut
loadings %>%
  select(tweet, PC3) %>%
  arrange(desc(PC3)) %>% 
  head()

```

Finally, PC4 shows a younger demographic, those interested in video games, sports, and college/university. The insight here for the brand is to target this market segment with branding aimed at youth and college-aged consumers. 

``` {r echo=F, results = T, warning = F}

# The college demographic - school, sports and video games
loadings %>%
  select(tweet, PC4) %>%
  arrange(desc(PC4)) %>% 
  head()

```

The other principle components begin to show less clear market segments, but some interesting ones still emerge. Consider PC7, which has high loadings in art, film, and crafts, or PC10, which seems to have a high interest in dating. 

``` {r echo=F, results = T, warning = F}
round(pca$rotation[,1:10],2)
```

Principle component analysis reveals some clear "ingredients" for each demographic, highlighting their interests, and giving valuable insight to the NutrientH2O marketing team to orient their strategy. 


## Problem 3 - Market Basket

```{r include=FALSE}
groceries_raw <- read.csv(here("Data/groceries.csv"),header = FALSE)

groceries <- groceries_raw %>% separate(V1, 
                        into =c("1","2","3","4","5","6","7","8",
                                "9","10","11","12","13","14","15","16",
                                "17","18","19","20","21","22","23","24","25",
                                "26","27","28","29","30","31","32"),
                                sep = ",")

groceries <- groceries %>% rownames_to_column(var = "customer") %>% 
  mutate(customer = as.factor(customer))

groceries <- pivot_longer(groceries,cols = !customer, 
                               names_to = "category",values_to = "grocery") %>% 
  filter(grocery != "")


groceries = split(x=groceries$grocery, f=as.factor(groceries$customer))

groceries= lapply(groceries, unique)

groc_carts = as(groceries, "transactions")
grocrules = apriori(groc_carts, 
                     parameter=list(support=.001, confidence=.05, maxlen=4))

```
Analyzing a grocery purchases is an extremely important task for grocery retailers. Understanding how products connect to certain consumers can allow the retailer to create product placement that a consumer will find useful. This creates a better experience for the consumer and helps increase sales and thus driving revenue up for the retailer. In this example we start with a data set that contains 9,835 consumer grocery baskets. The support level parameter essentially indicates the popularity of an item. When deciding the parameters we picked a support level of .001. The reasoning being that we wanted items to have appeared in approximately 10 consumers grocery carts. The confidence level is essentially the conditional probability of item x being purchased given the consumer has purchased item y. We set this level for at .05 to indicate that we wanted at least a 5% probability of a consumer purchasing one item conditional on them already purchasing another. When using these levels to create association rules we are left with 36,014 association rules. This is too many rules to make a sensible graph out of but lets look at some key plots first. 


```{r echo=FALSE,results=FALSE,warning=FALSE,message=FALSE}
plot(grocrules, method='two-key plot')
```

In this figure we see that our rules with length four have a large variance in confidence but low support. As we shorten the rule length, there we see less variance in confidence and a higher level of support. Again our current number of rules is too much to make a sensible graph. In order to construct a graph we will subset the rules looking for a confidence greater than 25% and support greater than 1%. This leaves us with 171 rules, now lets visualize these rules with a graph.

![](Homework4_files/figure-markdown_strict/graph.png)

This graph produces some results that are both interesting and seem reasonable. The colors on the graph represent the modularity class, the size of the nodes represents the support, and the size of the text represents the degree.  We see two main groups of consumers, those who purchase whole milk and those who purchase "other vegetable". We see a slightly smaller group of consumers purchasing yogurt and root vegetables as well. 